{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e56202",
   "metadata": {},
   "source": [
    "# RAG Workshop – Dutch Pension Law  \n",
    "Author: *Generated on 2025-04-30*  \n",
    "\n",
    "This notebook accompanies an internal workshop on **Retrieval‑Augmented Generation (RAG)** with Dutch pension‑related law texts from [wetten.overheid.nl](https://wetten.overheid.nl).  \n",
    "You will need:\n",
    "\n",
    "* Python 3.10+  \n",
    "* `openai`, `azure‑identity`, `langchain`, `langchain‑community`, `langchain‑huggingface`,`langchain_openai`, `tiktoken`, `rdflib`, `faiss-cpu`,`numpy`,`scikit-learn`,`time`,`textwrap`\n",
    "\n",
    "From an empty source folder in which you will run the notebook, run the following commands:\n",
    "\n",
    "1. **Clone & install**\n",
    "   ```bash\n",
    "   git init\n",
    "   python -m venv .venv && source .venv/bin/activate\n",
    "   git clone https://github.com/iAMLAB-test/workshop_llm\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "Using `config_template.yaml` fill it's contexts (provided seperately) and save under `config.yaml`:\n",
    "\n",
    "2. **Configure environment**\n",
    "   ```bash\n",
    "   API_KEY_DECODER: [Enter your API key here]\n",
    "   AZURE_ENDPOINT: [Enter your Azure endpoint here]\n",
    "   API_VERSION_DECODER: [Enter your API version here]\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd88990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pyvenv.cfg file\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c1e4d",
   "metadata": {},
   "source": [
    "### Simple LLM call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1039e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Prompting API example.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gpt_4o_mini\n\u001b[32m      4\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mSay \u001b[39m\u001b[33m'\u001b[39m\u001b[33mHello world\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in five different languages.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(gpt_4o_mini(query).choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\al.lee\\Downloads\\RAG_workshop\\src\\utils.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtiktoken\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myaml\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombine_documents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseCombineDocumentsChain\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquestion_answering\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_qa_chain\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "#Prompting API example.\n",
    "from utils import gpt_4o_mini\n",
    "\n",
    "query = \"Say 'Hello world' in five different languages.\"\n",
    "print(gpt_4o_mini(query).choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81016e16",
   "metadata": {},
   "source": [
    "## 1 – Layout of Dutch law texts  \n",
    "We will inspect local `.txt` dumps in `data/docs/`. Each file contains **one complete law** (some > 60 k tokens).\n",
    "\n",
    "Below we load the all three files and print a *single article* per file to understand the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f16bfcf",
   "metadata": {},
   "source": [
    "### Random article from input law texts.\n",
    "\n",
    "Here we show, using the three law texts, one random article from each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pensioenswet.txt, total articles 323 ---\n",
      "Artikel 150i.\n",
      "Implementatieplan  1.      In het implementatieplan legt de pensioenuitvoerder schriftelijk vast op\n",
      "welke wijze voorbereidingen worden getroffen voor de uitvoering van de gewijzigde\n",
      "pensioenovereenkomst en invulling zal worden gegeven aan de uitvoering van de gewijzigde\n",
      "pensioenovereenkomst, alsmede de wijze waarop zal worden omgegaan met opgebouwde pensioenaanspraken\n",
      "en pensioenrechten.  2.      Het implementatieplan bevat in ieder geval de volgende onderdelen:\n",
      "a.      de technische uitvoerbaarheid van de pensioenovereenkomst;         b.      de kosten die\n",
      "verband houden met de uitvoering van de pensioenovereenkomst;         c.      de risico’s die\n",
      "verband houden met de uitvoering van de pensioenovereenkomst;         d.      de\n",
      "risicobeheersmaatregelen die worden getroffen in verband met de uitvoering van de\n",
      "pensioenovereenkomst;         e.      de wijze waarop zal worden omgegaan met opgebouwde\n",
      "pensioenaanspraken en pensioenrechten;         f.      de wijze waarop uitvoering zal worden gegeven\n",
      "aan de pensioenovereenkomst met inachtneming van de toepasselijke wet- en regelgeving, waaronder de\n",
      "gelijkebehandelingswetgeving;         g.      een communicatieplan; en         h.      indien van\n",
      "toepassing, de effecten van het toepassen van het financieel toetsingskader tijdens de transitie en\n",
      "van toeslagverlening tussen 1 juli 2022 en de aanvang van de transitie op grond van de verwachting\n",
      "dat zal worden overgegaan tot een collectieve waardeoverdracht als bedoeld in artikel 150m.  3.\n",
      "Indien het implementatieplan wordt opgesteld door een pensioenfonds legt het pensioenfonds tevens\n",
      "vast, voor zover van toepassing, op welke wijze voorbereidingen worden getroffen voor en invulling\n",
      "zal worden gegeven aan de uitvoering van een besluit als bedoeld in artikel 150n.  4.      De\n",
      "pensioenuitvoerder stelt per pensioenregeling een implementatieplan op. In afwijking van de eerste\n",
      "zin kan een implementatieplan zich uitstrekken tot meerdere pensioenregelingen, voor zover de\n",
      "pensioenregelingen:         a.      bij uitvoering door een pensioenfonds: behoren tot hetzelfde\n",
      "financieel geheel; en         b.      bij uitvoering door verzekeraars of\n",
      "premiepensioeninstellingen: dezelfde karakteristieken hebben en gebaseerd zijn op hetzelfde\n",
      "producttype.  5.      De pensioenuitvoerder dient het implementatieplan binnen twee weken na de\n",
      "afronding in bij de toezichthouder. De pensioenuitvoerder stelt het implementatieplan op zijn\n",
      "website beschikbaar voor de deelnemer, gewezen deelnemer, gewezen partner en pensioengerechtigde.\n",
      "6.      Bij of krachtens algemene maatregel van bestuur worden nadere regels gesteld met betrekking\n",
      "tot dit artikel.\n",
      "\n",
      "--- Uitvoeringsbesluit loonbelasting 1965.txt, total articles 50 ---\n",
      "Artikel 10\n",
      "1.      In de premie, bedoeld in artikel 18a, eerste lid, van de wet, zijn kosten voor\n",
      "vermogensbeheer en voor het afdekken van beleggingsrisico’s begrepen. Het percentage van artikel\n",
      "18a, eerste lid, van de wet wordt verhoogd met overige kosten ten behoeve van een aanspraak\n",
      "ingevolge een pensioenregeling. De overige kosten, bedoeld in de tweede zin, kunnen niet worden\n",
      "aangewend voor een ouderdomspensioen en partnerpensioen bij overlijden op of na pensioendatum.  2.\n",
      "Het eerste lid is van overeenkomstige toepassing op de maximale premie, bedoeld in artikel 38r,\n",
      "eerste lid, van de wet.\n",
      "\n",
      "--- Wet op loonbelasting 1964.txt, total articles 169 ---\n",
      "Artikel 20\n",
      "1.      De over een loontijdvak van een jaar verschuldigde belasting is het bedrag van de over het\n",
      "kalenderjaar berekende belasting op het belastbare loon verminderd met het bedrag van de\n",
      "heffingskorting voor de loonbelasting.  2.      Het bedrag van de heffingskorting voor de\n",
      "loonbelasting bedraagt maximaal het bedrag van de verschuldigde belasting over het loontijdvak van\n",
      "een jaar.  3.      Voor werknemers die in een andere lidstaat van de Europese Unie, in een andere\n",
      "staat die partij is bij de Overeenkomst betreffende de Europese Economische Ruimte, in Zwitserland\n",
      "of op de BES eilanden wonen, wordt voor de toepassing van het eerste en tweede lid alleen het deel\n",
      "van de heffingskorting voor de loonbelasting dat betrekking heeft op de arbeidskorting in aanmerking\n",
      "genomen.  4.      Voor werknemers die niet in Nederland wonen en geen werknemer als bedoeld in het\n",
      "derde lid zijn, is, in afwijking van het eerste lid, de over een loontijdvak van een jaar\n",
      "verschuldigde belasting het bedrag van de over het kalenderjaar berekende belasting op het\n",
      "belastbare loon.  5.      Een werknemer die op grond van artikel 2.2, tweede of derde lid, van de\n",
      "Wet inkomstenbelasting 2001 geacht wordt in Nederland te wonen, wordt ook voor de toepassing van het\n",
      "derde en vierde lid geacht in Nederland te wonen.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from utils import split_articles, wrap_at_spaces\n",
    "\n",
    "# Load a law text file.\n",
    "DOC_PATH = Path(\"data/docs\")\n",
    "for law_file in sorted(DOC_PATH.glob(\"*.txt\")):\n",
    "    law_text = law_file.read_text(encoding=\"utf-8\")\n",
    "    articles = split_articles(law_text)  # drop preamble\n",
    "\n",
    "    example_idx = random.randrange(len(articles))\n",
    "    article_key = list(articles.keys())[example_idx]\n",
    "    print(f\"\\n--- {law_file.name}, total articles {len(articles)} ---\")\n",
    "    print(article_key)\n",
    "    print(wrap_at_spaces(articles[article_key],width=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb1b6e",
   "metadata": {},
   "source": [
    "### Count tokens per file.\n",
    "\n",
    "Given our working dataset, we show the number of tokens per law text below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbf9263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pensioenswet.txt: 126338 tokens\n",
      "Uitvoeringsbesluit loonbelasting 1965.txt: 20766 tokens\n",
      "Wet op loonbelasting 1964.txt: 64790 tokens\n",
      "\n",
      "Total tokens across all files: 211894\n"
     ]
    }
   ],
   "source": [
    "# Token count\n",
    "from utils import count_tokens_in_docs\n",
    "\n",
    "print(count_tokens_in_docs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280cb3d",
   "metadata": {},
   "source": [
    "## 2 – Direct LLM retrieval vs. Article‑wise retrieval  \n",
    "We compare:\n",
    "\n",
    "1. **Whole‑law prompt** – push the complete text (~60 k tokens)                                                 → costly ❌ fast ✔️ accurate ❌  \n",
    "2. **Chunked/article prompts** – iterate per article                                                            → costly ❌ slow ❌ accurate ✔️  \n",
    "3. **RAG** - use article text embeddings to identify five most relevant articles before searching per article   → cheap ✔️ fast ✔️ accurate ✔️  \n",
    "4. **Graph RAG** - Using a law text's linked-data structure                                                     → cheap ✔️ fast ✔️ accurate ✔️\n",
    "\n",
    "We demonstrates examples 3 and 4 at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3fb2b",
   "metadata": {},
   "source": [
    "### 2.1. First, using 'naive' full text chunking in one large system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb1b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Wat is de franchise, welk artikel gebruik je ervoor en wat zijn uitzonderingen op de wettelijke waarde? Hou het antwoord onder de 50 woorden.\n",
      "A: De franchise bedraagt € 18.475 volgens artikel 18a, tweede lid. Uitzonderingen op de wettelijke\n",
      "waarde gelden voor pensioenregelingen die niet voldoen aan de vereisten van de pensioenwet, of bij\n",
      "tijdelijke inactiviteit van de werknemer.\n",
      "\n",
      "--- Performance ---\n",
      "{\n",
      "  \"scenario\": \"Hele wetstekst ingeladen\",\n",
      "  \"input tokens\": 48515,\n",
      "  \"output tokens\": 53,\n",
      "  \"USD cost\": 0.014618,\n",
      "  \"elapsed seconds\": 3.584\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from utils import gpt_4o_mini, llm_metrics,wrap_at_spaces\n",
    "\n",
    "QUESTION = \"Wat is de franchise, welk artikel gebruik je ervoor en wat zijn uitzonderingen op de wettelijke waarde? Hou het antwoord onder de 50 woorden.\"\n",
    "\n",
    "# --- Whole law ---\n",
    "with open(\"data/docs/Wet op loonbelasting 1964.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    law_text = f.read()\n",
    "    start = time.time()\n",
    "    response = gpt_4o_mini(user_message=QUESTION,law_text = law_text)\n",
    "\n",
    "    elapsed = time.time()-start\n",
    "    out_tokens = response.usage.completion_tokens\n",
    "    in_tokens = response.usage.prompt_tokens\n",
    "    print(f\"Q {QUESTION}\")\n",
    "    print(f\"A: {wrap_at_spaces(response.choices[0].message.content,100)}\")\n",
    "    print(f\"\\n--- Performance ---\")\n",
    "    print(json.dumps(llm_metrics(\"Hele wetstekst ingeladen\", in_tokens, out_tokens, elapsed),indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65893cad",
   "metadata": {},
   "source": [
    "#### Answer incorrect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764d5f1",
   "metadata": {},
   "source": [
    "### 2.2. Second, by looping per article section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe405be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q Wat is de franchise, en wat zijn uitzonderingen op de wettelijke waarde? Indien deze tekst hier geen expliciete informatie over geeft, antwoord met enkel 'None'. Hou het antwoord onder de 50 woorden.\n",
      "A: De franchise bedraagt € 18.475, maar kan bij ministeriële regeling worden vervangen door een ander\n",
      "bedrag. Een lager bedrag kan worden vastgesteld indien een lager percentage per dienstjaar wordt\n",
      "toegepast dan het percentage genoemd in het eerste lid.\n",
      "\n",
      "--- Performance ---\n",
      "{\n",
      "  \"scenario\": \"Hele wetstekst ingeladen\",\n",
      "  \"input tokens\": 59330,\n",
      "  \"output tokens\": 434,\n",
      "  \"USD cost\": 0.01832,\n",
      "  \"elapsed seconds\": 48.723\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "from utils import gpt_4o_mini, llm_metrics,wrap_at_spaces,split_articles\n",
    "\n",
    "QUESTION = \"Wat is de franchise, en wat zijn uitzonderingen op de wettelijke waarde? \"+\\\n",
    "\"Indien deze tekst hier geen expliciete informatie over geeft, antwoord met enkel 'None'. Hou het antwoord onder de 50 woorden.\"\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "in_tokens,out_tokens = 0,0\n",
    "answers = []\n",
    "with open(\"data/docs/Wet op loonbelasting 1964.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    law_text = f.read()\n",
    "    article_dict = split_articles(law_text)\n",
    "    for key, law_article_text in article_dict.items():\n",
    "        response = gpt_4o_mini(user_message=QUESTION,law_text = law_article_text)\n",
    "        in_tokens += response.usage.prompt_tokens\n",
    "        out_tokens += response.usage.completion_tokens\n",
    "        if \"None\" in str(response.choices[0].message.content):\n",
    "            continue\n",
    "        answers.append((key,response.choices[0].message.content))\n",
    "    elapsed = time.time()-start\n",
    "    llm_metrics(\"Zoeken per artikel\", in_tokens, out_tokens, elapsed)\n",
    "    for key,ans in answers:\n",
    "        print(f\"Q {QUESTION}\")\n",
    "        print(f\"A: {wrap_at_spaces(ans,100)}\")\n",
    "        print(f\"\\n--- Performance ---\")\n",
    "        print(json.dumps(llm_metrics(\"Hele wetstekst ingeladen\", in_tokens, out_tokens, elapsed),indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9d673",
   "metadata": {},
   "source": [
    "#### Answer is correct, but takes a long time to find (50+ seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2b4fa",
   "metadata": {},
   "source": [
    "\n",
    "**Main observations**\n",
    "\n",
    "- The franchise value can be lower than € 18.475 given the premium percentage, this is only observed when looping over articles.\n",
    "- Looping over articles is accurate but takes a long time (50+ seconds in contrast to approximately 3 seconds). Both methods are costly, token-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef616e29",
   "metadata": {},
   "source": [
    "## 3. Introduction to RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d49064",
   "metadata": {},
   "source": [
    "\n",
    "A word/sentence embedding is a numerical representation (using a vector) of it's semantic meaning. \n",
    "\n",
    "By creating vector-stores of texts first, one no longer has to rely on word-matching or brute force loop-searching to find the right article containing specific text\n",
    "by simply searching over a small subset of articles with an embedding closest to the question at hand, which is RAG in a nutshell. \n",
    "\n",
    "Cosine similarity measures the (L2) distance between two vectors, in this case word/sentence embeddings. \n",
    "Values are between 0 and 1, with values closer to 1 indicating words/sentences that are similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f35043",
   "metadata": {},
   "source": [
    "### 3.1. Comparing embeddings ofwords/sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ec2bb",
   "metadata": {},
   "source": [
    "Change the model parameters to observe differences across similarity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c56a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- model: mxbai-embed-large-v1 ---\n",
      "t1: car\n",
      "t2: cat\n",
      "distance 0.7\n",
      "t1: cat \n",
      "t2: kitten \n",
      "distance 0.83\n",
      "t1: cat is a large animal\n",
      "t2: kitten is a large animal\n",
      "distance 0.89\n",
      "t1: cat is a large animal with much fur\n",
      "t2: kitten is a large animal with much fur\n",
      "distance 0.91\n",
      "---\n",
      "t1: rock\n",
      "t2: object that beats scissors in rock paper scissors\n",
      "distance 0.56\n",
      "t1: Tallest building in New York in 1931\n",
      "t2: The Empire State Building\n",
      "distance 0.68\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import text_embedding_3_large\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Adjustable parameters\n",
    "model = \"mxbai-embed-large-v1\" #\"mxbai-embed-large-v1\" or \"text_embedding_3_large\"\n",
    "\n",
    "assert model in [\"mxbai-embed-large-v1\",\"text_embedding_3_large\"], \"model must be either 'hf' or 'azure'\"\n",
    "mxbai_emb = HuggingFaceEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")\n",
    "#Test one, same sentence, one different word.\n",
    "print( \"--- model:\",model,\"---\")\n",
    "text_tuple_list = list([(\"car\",\"cat\")]+[(f\"cat {sentence}\",f\"kitten {sentence}\") for sentence in [\"\",\"is a large animal\", \"is a large animal with much fur\"]])\n",
    "for t1,t2 in text_tuple_list:\n",
    "    if model == \"mxbai-embed-large-v1\":\n",
    "        encoder_response = mxbai_emb.embed_documents([t1,t2])\n",
    "        v1,v2 = (np.array(encoder_response[i]).reshape(1,-1) for i in [0,1])\n",
    "    else:\n",
    "        encoder_response = text_embedding_3_large([t1,t2])\n",
    "        v1,v2 = (np.array(encoder_response.data[i].embedding).reshape(1,-1) for i in [0,1])\n",
    "    print(f\"t1: {t1}\")\n",
    "    print(f\"t2: {t2}\")\n",
    "    print(\"distance\",np.round(cosine_similarity(v1,v2)[0,0],2))\n",
    "\n",
    "#Test two, same meaning, different words.\n",
    "print( \"---\")\n",
    "text_tuple_list = list([(\"rock\",\"object that beats scissors in rock paper scissors\"),(\"Tallest building in New York in 1931\",\"The Empire State Building\")])\n",
    "for t1,t2 in text_tuple_list:\n",
    "    if model == \"mxbai-embed-large-v1\":\n",
    "        encoder_response = mxbai_emb.embed_documents([t1,t2])\n",
    "        v1,v2 = (np.array(encoder_response[i]).reshape(1,-1) for i in [0,1])\n",
    "    else:\n",
    "        encoder_response = text_embedding_3_large([t1,t2])\n",
    "        v1,v2 = (np.array(encoder_response.data[i].embedding).reshape(1,-1) for i in [0,1])\n",
    "    print(f\"t1: {t1}\")\n",
    "    print(f\"t2: {t2}\")\n",
    "    print(\"distance\",np.round(cosine_similarity(v1,v2)[0,0],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caccdc5c",
   "metadata": {},
   "source": [
    "**This cell demonstrates two things:**\n",
    "\n",
    "When keeping one word different but increasing the sentence size, the differing word leads to a smaller difference between the resulting embeddings.\n",
    "\n",
    "Distance between 'similar' sentences using the 'text_embedding_3_large' model seem to be further apart compared to the HuggingFaceEmbeddings 'mxbai-embed-large-v1' model.\n",
    "\n",
    "This can be tested by adjusting the 'model' parameter above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32857fec",
   "metadata": {},
   "source": [
    "### 3.2. Creating law article vector stores using both models (takes 3+ minutes on my developer-laptop), do not rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8b86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# import importlib,utils\n",
    "# importlib.reload(utils)\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# from utils import AZURE_EMBEDDINGS, MXBAI_EMBEDDINGS, split_articles\n",
    "# import os\n",
    "\n",
    "# dir_name = os.getcwd()\n",
    "\n",
    "# # Save law texts seperately to a list and create the underlying vector_stores\n",
    "# DOC_PATH = Path(\"data/docs\")\n",
    "# article_list = []\n",
    "# for law_file in sorted(DOC_PATH.glob(\"*.txt\")):\n",
    "#     law_text = law_file.read_text(encoding=\"utf-8\")\n",
    "#     articles = split_articles(law_text)  # drop preamble\n",
    "#     article_list += [f\"\"\"{law_file.name} {key} {value}\"\"\" for key,value in articles.items()]\n",
    "\n",
    "# # 20000 chosen because the largest law text is 18000 characters.\n",
    "# splitter = RecursiveCharacterTextSplitter(chunk_size=20000, chunk_overlap=0)\n",
    "# documents = splitter.create_documents(article_list)\n",
    "\n",
    "# # 'Vector stores', for now not stored efficiently (using FAISS langchain).\n",
    "# mxbai_store = FAISS.from_documents(documents, MXBAI_EMBEDDINGS,normalize_L2=True)\n",
    "# mxbai_store.save_local(os.path.join(dir_name,\"data/vector_stores/mxbai-embed-large-v1_nongraph.index\"))\n",
    "# azure_store = FAISS.from_documents(documents, AZURE_EMBEDDINGS,normalize_L2=True)\n",
    "# azure_store.save_local(os.path.join(dir_name,\"data/vector_stores/text-embedding-3-large_nongraph.index\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e7bc3",
   "metadata": {},
   "source": [
    "## 4. Demonstrating RAG using article vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87da14",
   "metadata": {},
   "source": [
    "### 4.1. For the generated vector store shows 5 of the most closely matched articles to the original question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8d9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 5 --- mixedbread-ai/mxbai-embed-large-v1\n",
      "Wet op loonbelasting 1964.txt Artikel 38s 1. Indien een pensioenregeling op grond van artikel 150f van de Pensioenwet of artikel 145e van de Wet [...]\n",
      "Wet op loonbelasting 1964.txt Artikel 18a 1. De premie per dienstjaar voor een ouderdomspensioen en een partnerpensioen bij overlijden op of na [...]\n",
      "Pensioenswet.txt Artikel 130. Vermelding premie in jaarrekening en bestuursverslag [Vervallen per 01-07-2023]\n",
      "Wet op loonbelasting 1964.txt Artikel 38m [Vervallen per 01-04-2017]\n",
      "Wet op loonbelasting 1964.txt Artikel 38j [Vervallen per 01-04-2017]\n",
      "\n",
      "--- Top 5 --- text_embedding_3_large\n",
      "Wet op loonbelasting 1964.txt Artikel 18a 1. De premie per dienstjaar voor een ouderdomspensioen en een partnerpensioen bij overlijden op of na [...]\n",
      "Pensioenswet.txt Artikel 150l. Standaard invaarpad 1. De wijze waarop wordt omgegaan met opgebouwde pensioenaanspraken en pensioenrechten als [...]\n",
      "Wet op loonbelasting 1964.txt Artikel 13 1. Niet in geld genoten loon wordt in aanmerking genomen naar de waarde die daaraan in het economische [...]\n",
      "Pensioenswet.txt Artikel 67. Afkoop klein partnerpensioen of wezenpensioen bij ingang 1. De pensioenuitvoerder heeft jegens de nabestaanden het [...]\n",
      "Pensioenswet.txt Artikel 79. Plicht tot waardeaanwending bij keuzerecht of keuzemogelijkheid 1. De pensioenuitvoerder is verplicht om op verzoek [...]\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import importlib,utils\n",
    "importlib.reload(utils)\n",
    "from utils import MXBAI_STORE_NONGRAPH, AZURE_STORE_NONGRAPH, topk\n",
    "\n",
    "# number of articles to check\n",
    "n = 5\n",
    "\n",
    "QUESTION = \"Wat is de franchise, welk artikel gebruik je ervoor en wat zijn uitzonderingen op de wettelijke waarde? Hou het antwoord onder de 50 woorden.\"\n",
    "v1 = topk(MXBAI_STORE_NONGRAPH,QUESTION,k=n)\n",
    "v2 = topk(AZURE_STORE_NONGRAPH,QUESTION,k=n)\n",
    "\n",
    "article_list_mxbai = [tup[0].page_content for tup in v1]\n",
    "article_list_azure = [tup[0].page_content for tup in v2]\n",
    "\n",
    "# Pair them distance-first so heapq.nlargest uses the distance as the key\n",
    "dist_list = list(zip([\"mixedbread-ai/mxbai-embed-large-v1\",\"text_embedding_3_large\"],[article_list_mxbai, article_list_azure]))\n",
    "for name,article_list in dist_list:\n",
    "    print(f\"\\n--- Top {n} --- {name}\")\n",
    "    for article in article_list:\n",
    "        print(f\"{textwrap.shorten(article,150)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d60006",
   "metadata": {},
   "source": [
    "#### Article 18a of 'Wet op loonbelasting 1964' is the correct article.\n",
    "\n",
    "The 'text_embedding_3_large' model ranks it first, 'mixedbread-ai/mxbai-embed-large-v1' model ranks it second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47ac57",
   "metadata": {},
   "source": [
    "### 4.2. Putting everything together, using mxbai encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e4ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Wat is de franchise, welk artikel gebruik je ervoor en wat zijn uitzonderingen op de wettelijke waarde? Hou het antwoord onder de 50 woorden.\n",
      "A: De franchise bedraagt € 18.475, zoals vermeld in Artikel 18a, lid 3 van de Wet op loonbelasting 1964. Uitzonderingen zijn mogelijk bij deeltijdwerk en indien een lager percentage per dienstjaar wordt toegepast.\n",
      "\n",
      "--- Top 5 documents ---\n",
      "Wet op loonbelasting 1964.txt Artikel 38s 1. Indien een pensioenregeling op grond van artikel 150f van de Pensioenwet of artikel 145e van de Wet [...]\n",
      "Wet op loonbelasting 1964.txt Artikel 18a 1. De premie per dienstjaar voor een ouderdomspensioen en een partnerpensioen bij overlijden op of na [...]\n",
      "Pensioenswet.txt Artikel 130. Vermelding premie in jaarrekening en bestuursverslag [Vervallen per 01-07-2023]\n",
      "Wet op loonbelasting 1964.txt Artikel 38m [Vervallen per 01-04-2017]\n",
      "Wet op loonbelasting 1964.txt Artikel 38j [Vervallen per 01-04-2017]\n",
      "\n",
      "--- Performance ---\n",
      "{\n",
      "  \"scenario\": \"RAG op wetsartikelen\",\n",
      "  \"input tokens\": 1738,\n",
      "  \"output tokens\": 50,\n",
      "  \"USD cost\": 0.000581,\n",
      "  \"elapsed seconds\": 2.054\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import textwrap\n",
    "import json\n",
    "from langchain_community.callbacks import get_openai_callback\n",
    "from utils import rag_executor, MXBAI_STORE_NONGRAPH\n",
    "\n",
    "start = time.time()\n",
    "QUESTION = \"Wat is de franchise, welk artikel gebruik je ervoor en wat zijn uitzonderingen op de wettelijke waarde? Hou het antwoord onder de 50 woorden.\"\n",
    "answer,top_docs,qa_chain = rag_executor(QUESTION,store = MXBAI_STORE_NONGRAPH)\n",
    "print(\"Q:\", QUESTION)\n",
    "print(\"A:\", answer)\n",
    "print(f\"\\n--- Top {len(top_docs)} documents ---\")\n",
    "for doc in top_docs:\n",
    "    print(f\"{textwrap.shorten(str(doc.page_content),150)}\")\n",
    "\n",
    "print(f\"\\n--- Performance ---\")\n",
    "with get_openai_callback() as cb:\n",
    "    answer = qa_chain.invoke({\"input_documents\": top_docs, \"question\": QUESTION})\n",
    "    in_tokens = cb.prompt_tokens\n",
    "    out_tokens = cb.completion_tokens\n",
    "    elapsed = time.time()-start\n",
    "print(json.dumps(llm_metrics(\"RAG op wetsartikelen\", in_tokens, out_tokens, elapsed),indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c70f58",
   "metadata": {},
   "source": [
    "#### Much faster and accurate compared to the methods in Section 2.1 or 2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d4a49",
   "metadata": {},
   "source": [
    "## 5. Graph RAG, taking advantage of linked data structure for RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831d282",
   "metadata": {},
   "source": [
    "### 5.1. Law graph (created beforehand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c688dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Placeholder, visualize graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca18065",
   "metadata": {},
   "source": [
    "### 5.2. Graph-based vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2605c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Placeholder, create vector stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691a423d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Placeholder, display top 5 articles based on a query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf3321d",
   "metadata": {},
   "source": [
    "### 5.3. Questions across articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: RAG demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3808b3",
   "metadata": {},
   "source": [
    "## Wrap‑up / Key takeaways ✅  \n",
    "\n",
    "* **Direct prompting** on entire laws is cost‑heavy and hits context limits.  \n",
    "* **Chunking** improves alignment but sacrifices latency.  \n",
    "* **RAG** with a high‑quality embedding model (MXBAI) gives the *best accuracy‑per‑dollar*.  \n",
    "* Integrating domain‑specific knowledge graphs can further boost recall for cross‑article references.  \n",
    "\n",
    "Feel free to extend the notebook by  \n",
    "* replacing placeholder accuracies with manual grading,  \n",
    "* adding caching for embeddings,  \n",
    "* deploying the FAISS index as an API.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
