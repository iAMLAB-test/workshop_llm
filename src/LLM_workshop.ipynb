{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccad53b1",
   "metadata": {},
   "source": [
    "# LLM Training Notebook\n",
    "\n",
    "This notebook accompanies an internal training session on Utilizing Large Language Models (LLMs).\n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this session, you should understand:\n",
    "- How to call LLMs programmatically using different frameworks (e.g., OpenAI, HuggingFace, local models).\n",
    "- The structure of responses returned by LLM APIs.\n",
    "- Best practices for prompt construction.\n",
    "- Prompt templating.\n",
    "- How function calling works with modern LLM APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680175ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a13b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Import \\\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(__name__), \"..\"))\n",
    "config_path = os.path.join(parent_dir, \"config.yaml\")\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3e3fa1",
   "metadata": {},
   "source": [
    "## Calling LLMs\n",
    "\n",
    "In this section, we will learn how to programmatically call Large Language Models (LLMs) using `python`.\n",
    "\n",
    "There are multiple ways to do this, but the most straightforward method is using the `openai` package to interact with a hosted LLM provided by a cloud platform such as **Azure OpenAI** or **OpenAI** directly.\n",
    "\n",
    "Most LLM APIs follow a standardized **chat-based interface**, in which messages are exchanged using roles:\n",
    "- `system`: provides initial instructions or context to the model (e.g., \"You are a helpful assistant.\")\n",
    "- `user`: represents queries or instructions from the user.\n",
    "- `assistant`: responses generated by the LLM (only used in multi-turn history).\n",
    "\n",
    "This role-based structure helps the model interpret intent and maintain context.\n",
    "\n",
    "### 2.1 OpenAI (Hosted on Azure)\n",
    "\n",
    "Azure OpenAI provides enterprise-grade access to OpenAI models, including GPT-3.5 and GPT-4, with additional benefits like regional hosting, RBAC, and cost management.\n",
    "\n",
    "#### Step 1: Deploy a model on Azure\n",
    "\n",
    "Before you can use an Azure-hosted model, you need to:\n",
    "1. Create an Azure OpenAI resource.\n",
    "2. Deploy a model (e.g., `gpt-35-turbo`, `gpt-4`) within that resource.\n",
    "3. Note the following values from your deployment:\n",
    "   - **Endpoint URI** (e.g., `https://your-resource.openai.azure.com/`)\n",
    "   - **API Key**\n",
    "   - **Deployment Name** (the identifier you gave your model)\n",
    "   - **API Version** (e.g., `2024-03-01-preview`)\n",
    "\n",
    "Using these settings in the `config_template.yaml`, we can now generate a client to have a back-and-forth with an LLM on Azure.\n",
    "\n",
    "#### Step 2: Generate a client and test the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929816d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_version=\"2023-07-01-preview\",\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\") or \"asd\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_API_ENDPOINT\") or \"http://asd\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # Name we gave the deployment in Azure.\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\") or \"gpt-4o\",\n",
    "    # The full list of messages to send to the model.\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You will talk like a pirate.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a joke.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51eb86",
   "metadata": {},
   "source": [
    "#### Step 3: Let's take a look at the output structure\n",
    "\n",
    "Now that we have a `completion`, we can investigate what was retrieved from the API call.\n",
    "\n",
    "The `completion` object returned by `client.chat.completions.create` is a Python dictionary with a standardized structure. Here’s how you can inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96043e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(completion, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26657564",
   "metadata": {},
   "source": [
    "Key fields to note:\n",
    "- choices: A list of one or more completion options. Each contains:\n",
    "- index: Position of this choice in the list.\n",
    "- message: The actual response, with role and content.\n",
    "- finish_reason: Indicates why the model stopped generating (e.g., \"stop\", \"length\", or \"function_call\").\n",
    "- usage: Token counts for prompt and completion. Useful for monitoring usage and cost.\n",
    "- id, created, model: Metadata about the request.\n",
    "\n",
    "Understanding this structure is essential when post-processing responses, logging, or chaining prompts.\n",
    "\n",
    "## Best practices - Prompt structure\n",
    "\n",
    "Writing effective prompts is one of the most important skills when working with LLMs. The quality, clarity, and intent of your prompt heavily influence the model's output.\n",
    "\n",
    "While specific models (e.g., OpenAI's `gpt-4` vs. open-source LLMs) may benefit from tailored prompt engineering, there are general best practices that apply broadly.\n",
    "\n",
    "Let’s walk through these using an example task: **asking an LLM to perform a code review of a small function**.\n",
    "\n",
    "Our initial naive prompt is `Review my code`.\n",
    "This is too vague and will likely result in a generic or superficial response.\n",
    "\n",
    "### 1. Be explicit and specific\n",
    "\n",
    "Give the model enough context to interpret the request meaningfully.\n",
    "\n",
    "**Improved prompt:**\n",
    "```text\n",
    "You are an expert senior full-stack developer. You must perform an in-depth code review of the following Python function, focusing on correctness, best practices, computational efficiency, and clarity. Do not rewrite the code; only comment where improvements can be made.\n",
    "```\n",
    "\n",
    "### 2. Define output structure\n",
    "\n",
    "Explicitly define the format of the output to ensure it's consistent and useful for downstream consumption or integration.\n",
    "\n",
    "```text\n",
    "Respond using the following structure:\n",
    "- Summary: A concise overview of the function’s quality.\n",
    "- Strengths: A bullet list of well-implemented aspects.\n",
    "- Suggestions: A bullet list of potential improvements, each with justification.\n",
    "- Severity: Indicate impact level for each suggestion (Low / Medium / High).\n",
    "```\n",
    "\n",
    "### 3. Use Constraints\n",
    "\n",
    "Control verbosity, structure, tone, or language explicitly.\n",
    "\n",
    "```text\n",
    "Limit the answer to 100 words and avoid technical jargon.\n",
    "Respond in Dutch.\n",
    "Use only Markdown for formatting.\n",
    "```\n",
    "\n",
    "### 4. Ask for Chain-Of-Thought (CoT)\n",
    "\n",
    "Encourage the model to reason explicitly before answering. This is particularly useful in complex problem-solving and debugging tasks.\n",
    "\n",
    "```text\n",
    "Think step-by-step before proposing improvements. Explain your reasoning as if teaching a junior developer.\n",
    "```\n",
    "\n",
    "### 5. Set Success Criteria\n",
    "\n",
    "Tell the model what a \"good\" response looks like.\n",
    "\n",
    "```text\n",
    "The ideal output is clear, concise, and actionable. It should be easily understood by a mid-level software engineer.\n",
    "```\n",
    "\n",
    "### 6. Use Few-shot Examples to Set Expectations\n",
    "\n",
    "Provide 1–2 examples of inputs and desired outputs before your actual task.\n",
    "This technique can dramatically improve performance on repetitive tasks or formatting-sensitive outputs.\n",
    "\n",
    "\n",
    "### 7. Chain Prompts When Needed\n",
    "\n",
    "Split complex workflows into smaller, manageable prompts. LLMs are generally more accurate when dealing with a narrow, well-defined scope.\n",
    "\n",
    "Example workflow:\n",
    "1.\tFirst prompt: Extract and summarize function purpose.\n",
    "2.\tSecond prompt: Identify inefficiencies or bugs.\n",
    "3.\tThird prompt: Suggest performance improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f85adc",
   "metadata": {},
   "source": [
    "## Final prompt example\n",
    "\n",
    "```text\n",
    "You are an expert senior full-stack developer. You must perform an in-depth code review of the following Python function, focusing on correctness, best practices, computational efficiency, and clarity.\n",
    "\n",
    "Focus on:\n",
    "- Correctness\n",
    "- Computational efficiency\n",
    "- Pythonic best practices\n",
    "- Code clarity and maintainability\n",
    "\n",
    "Constraints:\n",
    "- Do not rewrite the code.\n",
    "- Use only Markdown formatting.\n",
    "- Limit your response to 200 words.\n",
    "- Use clear, professional language.\n",
    "\n",
    "Respond using this structure:\n",
    "- **Summary**: One or two sentences summarizing the review.\n",
    "- **Strengths**: Bullet list of good practices observed.\n",
    "- **Suggestions**: Bullet list of improvements, each with a brief justification.\n",
    "- **Severity**: Label each suggestion as Low / Medium / High.\n",
    "\n",
    "The goal is to produce feedback that is clear, actionable, and helpful for a mid-level developer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797b8f7",
   "metadata": {},
   "source": [
    "## Prompt Templating\n",
    "\n",
    "For general prompts that need to be reused across multiple inputs or tasks, **prompt templating** is a powerful technique. It allows you to define a reusable prompt structure and dynamically insert task-specific input at runtime. Prompt templating is fundamental for scalable LLM workflows—whether you're building chatbots, pipelines, or tools that generate or analyze structured text.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0b305",
   "metadata": {},
   "source": [
    "### Example: Code Review Prompt Template\n",
    "\n",
    "Suppose you want to review multiple code snippets using the same prompt pattern. You can define a template with placeholders and fill it dynamically.\n",
    "For instance, we define two placeholders: `n_words` and `code` which we fill afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613b8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = \"\"\"\n",
    "    You are a senior full-stack engineer specializing in Python. Perform an in-depth code review of the following function.\n",
    "\n",
    "    Focus on:\n",
    "    - Correctness\n",
    "    - Computational efficiency\n",
    "    - Pythonic best practices\n",
    "    - Code clarity and maintainability\n",
    "\n",
    "    Constraints:\n",
    "    - Do not rewrite the code.\n",
    "    - Use only Markdown formatting.\n",
    "    - Limit your response to {n_words} words.\n",
    "    - Use clear, professional language.\n",
    "\n",
    "    Respond using this structure:\n",
    "    - **Summary**: One or two sentences summarizing the review.\n",
    "    - **Strengths**: Bullet list of good practices observed.\n",
    "    - **Suggestions**: Bullet list of improvements, each with a brief justification.\n",
    "    - **Severity**: Label each suggestion as Low / Medium / High.\n",
    "\n",
    "    Code:\n",
    "    ```python\n",
    "    {code}\n",
    "    ```\n",
    "\"\"\"\n",
    "\n",
    "## Use the prompt template and fill with example code and n_words\n",
    "n_words = 100\n",
    "code = \"\"\"\n",
    "def calculate_sum(numbers):\n",
    "    total = 0\n",
    "    for number in numbers:\n",
    "        total += number\n",
    "    return total\n",
    "\"\"\"\n",
    "\n",
    "prompt_filled = prompt_template.format(n_words=n_words, code=code)\n",
    "\n",
    "# Create a chat completion using the prompt\n",
    "completion = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\") or \"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a senior full-stack engineer specializing in Python.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt_filled,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800242a4",
   "metadata": {},
   "source": [
    "## Function Calling\n",
    "\n",
    "Not all tasks should be delegated to an LLM—especially simple, deterministic operations like summing numbers or counting the occurrence of a specific character in a string. While LLMs are powerful, they are not guaranteed to be accurate on arithmetic or token-level operations due to their probabilistic nature.\n",
    "\n",
    "Instead, we can combine the strengths of LLMs with traditional code by using **function calling**.\n",
    "\n",
    "### Concept\n",
    "\n",
    "Use the LLM to interpret the user's intent and decide *which* function to call, but let actual logic and computation be handled by explicitly defined code.\n",
    "\n",
    "This pattern is especially useful in:\n",
    "\n",
    "- Natural language interfaces\n",
    "- Assistants and agents\n",
    "- Chatbots that need reliable outputs for certain tasks\n",
    "\n",
    "### Example: Count letter occurrences\n",
    "\n",
    "Let’s say the user asks:\n",
    "How many times does the letter ‘r’ appear in the word ‘strawberrry’?\n",
    "> (Note: the word contains a typo with **4 r’s**, not 3.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1add7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\") or \"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Count the number of r's in the text.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"strawberrry\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a807b8bb",
   "metadata": {},
   "source": [
    "\n",
    "Rather than trusting the LLM to count letters directly, we define a function to do this reliably and we will provide the model with additional context into what that function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# --- Function we want to call ---\n",
    "def count_letter(word: str, letter: str) -> int:\n",
    "    return word.count(letter)\n",
    "\n",
    "\n",
    "# --- Function schema (OpenAI format) ---\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"count_letter\",\n",
    "        \"description\": \"Count how many times a letter appears in a word.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"word\": {\"type\": \"string\", \"description\": \"The word to inspect\"},\n",
    "                \"letter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The single character to count\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"word\", \"letter\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# --- Call the model with function-calling enabled ---\n",
    "completion = client.chat.completions.create(\n",
    "    model=os.getenv(\"AZURE_OPENAI_MODEL_NAME\") or \"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How many times does the letter 'r' appear in the word 'strawberrry'?\",\n",
    "        }\n",
    "    ],\n",
    "    # We add the function schema to the request\n",
    "    tools=functions,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Process the model's response\n",
    "choice = completion.choices[0]\n",
    "\n",
    "# --- If the model chose a function to call, do it in Python ---\n",
    "if choice.message.function_call:\n",
    "    # Get the function name and arguments\n",
    "    function_name = choice.message.function_call.name\n",
    "    function_args = json.loads(choice.message.function_call.arguments)\n",
    "\n",
    "    # Call the function with the arguments\n",
    "    result = globals()[function_name](**function_args)\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Function '{function_name}' returned: {result}\")\n",
    "# --- If the model didn't choose a function, print the message ---\n",
    "else:\n",
    "    print(f\"Model response: {choice.message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
